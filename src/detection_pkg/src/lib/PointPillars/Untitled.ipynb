{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46cd75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "from utils import setup_seed, read_points, read_calib, read_label, \\\n",
    "    keep_bbox_from_image_range, keep_bbox_from_lidar_range, vis_pc, \\\n",
    "    vis_img_3d, bbox3d2corners_camera, points_camera2image, \\\n",
    "    bbox_camera2lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9159529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_range_filter(pts, point_range=[0, -39.68, -3, 69.12, 39.68, 1]):\n",
    "    '''\n",
    "    data_dict: dict(pts, gt_bboxes_3d, gt_labels, gt_names, difficulty)\n",
    "    point_range: [x1, y1, z1, x2, y2, z2]\n",
    "    논문에 표기된 대로 car, pedstrian cyclist를 검출하는 포인터 범위\n",
    "    '''\n",
    "    flag_x_low = pts[:, 0] > point_range[0] # 0\n",
    "    flag_y_low = pts[:, 1] > point_range[1] # -39.68\n",
    "    flag_z_low = pts[:, 2] > point_range[2] # -3\n",
    "    flag_x_high = pts[:, 0] < point_range[3] # 69.12\n",
    "    flag_y_high = pts[:, 1] < point_range[4] # 39.68\n",
    "    flag_z_high = pts[:, 2] < point_range[5] # 1\n",
    "    keep_mask = flag_x_low & flag_y_low & flag_z_low & flag_x_high & flag_y_high & flag_z_high\n",
    "    pts = pts[keep_mask]\n",
    "    return pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.anchors import Anchors, anchor_target, anchors2bboxes\n",
    "from ops import Voxelization, nms_cuda\n",
    "from utils import limit_period\n",
    "\n",
    "\n",
    "class PillarLayer(nn.Module):\n",
    "    def __init__(self, voxel_size, point_cloud_range, max_num_points, max_voxels):\n",
    "        super().__init__()\n",
    "        self.voxel_layer = Voxelization(voxel_size=voxel_size,\n",
    "                                        point_cloud_range=point_cloud_range,\n",
    "                                        max_num_points=max_num_points,\n",
    "                                        max_voxels=max_voxels)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, batched_pts):\n",
    "        '''\n",
    "        batched_pts: list[tensor], len(batched_pts) = bs\n",
    "        return: \n",
    "               pillars: (p1 + p2 + ... + pb, num_points, c), \n",
    "               coors_batch: (p1 + p2 + ... + pb, 1 + 3), \n",
    "               num_points_per_pillar: (p1 + p2 + ... + pb, ), (b: batch size)\n",
    "        '''\n",
    "        pillars, coors, npoints_per_pillar = [], [], []\n",
    "        for i, pts in enumerate(batched_pts):\n",
    "            voxels_out, coors_out, num_points_per_voxel_out = self.voxel_layer(pts) \n",
    "            # voxels_out: (max_voxel, num_points, c), coors_out: (max_voxel, 3)\n",
    "            # num_points_per_voxel_out: (max_voxel, )\n",
    "            pillars.append(voxels_out)\n",
    "            coors.append(coors_out.long())\n",
    "            npoints_per_pillar.append(num_points_per_voxel_out)\n",
    "        \n",
    "        pillars = torch.cat(pillars, dim=0) # (p1 + p2 + ... + pb, num_points, c)\n",
    "        npoints_per_pillar = torch.cat(npoints_per_pillar, dim=0) # (p1 + p2 + ... + pb, )\n",
    "        coors_batch = []\n",
    "        for i, cur_coors in enumerate(coors):\n",
    "            coors_batch.append(F.pad(cur_coors, (1, 0), value=i))\n",
    "        coors_batch = torch.cat(coors_batch, dim=0) # (p1 + p2 + ... + pb, 1 + 3)\n",
    "\n",
    "        return pillars, coors_batch, npoints_per_pillar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919dba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_folder_path = \"dataset/testing/velodyne/\"\n",
    "pc_file_list = os.listdir(pc_folder_path)\n",
    "pc = read_points(pc_folder_path + \"/\" + pc_file_list[0])\n",
    "\n",
    "pc = point_range_filter(pc)\n",
    "# pc_torch = torch.from_numpy(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f415f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8599, 32, 4])\n",
      "torch.Size([8599, 4])\n",
      "torch.Size([8599])\n",
      "tensor([[20.3780,  4.6160,  0.9160,  0.3900],\n",
      "        [20.4490,  4.5740,  0.7840,  0.2900],\n",
      "        [20.3510,  4.6190,  0.7820,  0.3900],\n",
      "        [20.4170,  4.5080,  0.4190,  0.2600],\n",
      "        [20.3700,  4.5640,  0.4180,  0.3900],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
      "tensor([  0, 127, 276,   0], device='cuda:0')\n",
      "tensor(5, device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # np.random.seed(22)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    nclasses=3\n",
    "    voxel_size=[0.16, 0.16, 4]\n",
    "    point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1]\n",
    "    max_num_points=32\n",
    "    max_voxels=(16000, 40000)\n",
    "\n",
    "    test_layer = PillarLayer(voxel_size=voxel_size,\n",
    "                            point_cloud_range=point_cloud_range,\n",
    "                            max_voxels=max_voxels,\n",
    "                            max_num_points=max_num_points)\n",
    "\n",
    "    # pc = np.random.uniform(-2, 8, size=[1000, 4]).astype(np.float32)\n",
    "    pc_tensor = torch.from_numpy(pc).to(device)\n",
    "\n",
    "    pillars, coors_batch, npoints_per_pillar = test_layer([pc_tensor])\n",
    "\n",
    "    print(pillars.size())\n",
    "    print(coors_batch.size())\n",
    "    print(npoints_per_pillar.size())\n",
    "\n",
    "    print(pillars[10])\n",
    "    print(coors_batch[10])\n",
    "    print(npoints_per_pillar[10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37c234c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx, vy = voxel_size[0], voxel_size[1]\n",
    "x_offset = voxel_size[0] / 2 + point_cloud_range[0]\n",
    "y_offset = voxel_size[1] / 2 + point_cloud_range[1]\n",
    "\n",
    "offset_pt_center = pillars[:, :, :3] - torch.sum(pillars[:, :, :3], dim=1, keepdim=True) / npoints_per_pillar[:, None, None] \n",
    "x_offset_pi_center = pillars[:, :, :1] - (coors_batch[:, None, 1:2] * vx + x_offset) # (p1 + p2 + ... + pb, num_points, 1)\n",
    "y_offset_pi_center = pillars[:, :, 1:2] - (coors_batch[:, None, 2:3] * vy + y_offset) # (p1 + p2 + ... + pb, num_points, 1)\n",
    "\n",
    "\n",
    "features = torch.cat([pillars, offset_pt_center, x_offset_pi_center, y_offset_pi_center], dim=-1) # (p1 + p2 + ... + pb, num_points, 9)\n",
    "features[:, :, 0:1] = x_offset_pi_center # tmp\n",
    "features[:, :, 1:2] = y_offset_pi_center # tmp\n",
    "\n",
    "# voxel_ids = torch.arange(0, pillars.size(1)).to(device) # (num_points, )\n",
    "# mask = voxel_ids[:, None] < npoints_per_pillar[None, :] # (num_points, p1 + p2 + ... + pb)\n",
    "# mask = mask.permute(1, 0).contiguous()  # (p1 + p2 + ... + pb, num_points)\n",
    "# features *= mask[:, :, None]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be28663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(9, 64, 1, bias=False).to(device)\n",
    "bn = nn.BatchNorm1d(64, eps=1e-3, momentum=0.01).to(device)\n",
    "# 5. embedding\n",
    "features = features.permute(0, 2, 1).contiguous()\n",
    "features = F.relu(bn(conv(features)))  # (p1 + p2 + ... + pb, out_channels, num_points)\n",
    "pooling_features = torch.max(features, dim=-1)[0] # (p1 + p2 + ... + pb, out_channels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed0cb3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8599, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16ac5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_canvas = []\n",
    "bs = coors_batch[-1, 0] + 1\n",
    "\n",
    "x_l = int((point_cloud_range[3] - point_cloud_range[0]) / voxel_size[0])\n",
    "y_l = int((point_cloud_range[4] - point_cloud_range[1]) / voxel_size[1])\n",
    "\n",
    "for i in range(bs):\n",
    "    cur_coors_idx = coors_batch[:, 0] == i\n",
    "    cur_coors = coors_batch[cur_coors_idx, :]\n",
    "    cur_features = pooling_features[cur_coors_idx]\n",
    "    canvas = torch.zeros((x_l, y_l, 64), dtype=torch.float32, device=device)\n",
    "    canvas[cur_coors[:, 1], cur_coors[:, 2]] = cur_features\n",
    "    canvas = canvas.permute(2, 1, 0).contiguous()\n",
    "    batched_canvas.append(canvas)\n",
    "batched_canvas = torch.stack(batched_canvas, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cff916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel=64\n",
    "out_channels=[64, 128, 256]\n",
    "layer_nums=[3, 5, 5]\n",
    "layer_strides=[2, 2, 2]\n",
    "\n",
    "for i in range(len(layer_strides)):\n",
    "    blocks = []\n",
    "    blocks.append(nn.Conv2d(in_channel, out_channels[i], 3, stride=layer_strides[i], bias=False, padding=1))\n",
    "    blocks.append(nn.BatchNorm2d(out_channels[i], eps=1e-3, momentum=0.01))\n",
    "    blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "    for _ in range(layer_nums[i]):\n",
    "        blocks.append(nn.Conv2d(out_channels[i], out_channels[i], 3, bias=False, padding=1))\n",
    "        blocks.append(nn.BatchNorm2d(out_channels[i], eps=1e-3, momentum=0.01))\n",
    "        blocks.append(nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30b8423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = nn.Conv2d(64, 64, 3, stride=2, bias=False, padding=1).to(device)\n",
    "a13 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "a14 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "a15 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "\n",
    "b1 = nn.ConvTranspose2d(64, 128, 1, stride=1, bias=False).to(device)\n",
    "\n",
    "c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66017eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = a1(batched_canvas)\n",
    "test = b1(test)\n",
    "\n",
    "# test = a12(batched_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ff592e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 248, 216])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 40, feature_map_size[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b6000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pillars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a272d058f02466131663a98fde0a5fb028fb2427dbe553090c2dd1c9aa10e44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
