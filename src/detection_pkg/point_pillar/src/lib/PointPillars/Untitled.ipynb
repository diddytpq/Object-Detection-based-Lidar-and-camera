{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cd75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "from utils import setup_seed, read_points, read_calib, read_label, \\\n",
    "    keep_bbox_from_image_range, keep_bbox_from_lidar_range, vis_pc, \\\n",
    "    vis_img_3d, bbox3d2corners_camera, points_camera2image, \\\n",
    "    bbox_camera2lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9159529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_range_filter(pts, point_range=[0, -39.68, -3, 69.12, 39.68, 1]):\n",
    "    '''\n",
    "    data_dict: dict(pts, gt_bboxes_3d, gt_labels, gt_names, difficulty)\n",
    "    point_range: [x1, y1, z1, x2, y2, z2]\n",
    "    논문에 표기된 대로 car, pedstrian cyclist를 검출하는 포인터 범위\n",
    "    '''\n",
    "    flag_x_low = pts[:, 0] > point_range[0] # 0\n",
    "    flag_y_low = pts[:, 1] > point_range[1] # -39.68\n",
    "    flag_z_low = pts[:, 2] > point_range[2] # -3\n",
    "    flag_x_high = pts[:, 0] < point_range[3] # 69.12\n",
    "    flag_y_high = pts[:, 1] < point_range[4] # 39.68\n",
    "    flag_z_high = pts[:, 2] < point_range[5] # 1\n",
    "    keep_mask = flag_x_low & flag_y_low & flag_z_low & flag_x_high & flag_y_high & flag_z_high\n",
    "    pts = pts[keep_mask]\n",
    "    return pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dc3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.anchors import Anchors, anchor_target, anchors2bboxes\n",
    "from ops import Voxelization, nms_cuda\n",
    "from utils import limit_period\n",
    "\n",
    "\n",
    "class PillarLayer(nn.Module):\n",
    "    def __init__(self, voxel_size, point_cloud_range, max_num_points, max_voxels):\n",
    "        super().__init__()\n",
    "        self.voxel_layer = Voxelization(voxel_size=voxel_size,\n",
    "                                        point_cloud_range=point_cloud_range,\n",
    "                                        max_num_points=max_num_points,\n",
    "                                        max_voxels=max_voxels)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, batched_pts):\n",
    "        '''\n",
    "        batched_pts: list[tensor], len(batched_pts) = bs\n",
    "        return: \n",
    "               pillars: (p1 + p2 + ... + pb, num_points, c), \n",
    "               coors_batch: (p1 + p2 + ... + pb, 1 + 3), \n",
    "               num_points_per_pillar: (p1 + p2 + ... + pb, ), (b: batch size)\n",
    "        '''\n",
    "        pillars, coors, npoints_per_pillar = [], [], []\n",
    "        for i, pts in enumerate(batched_pts):\n",
    "            voxels_out, coors_out, num_points_per_voxel_out = self.voxel_layer(pts) \n",
    "            # voxels_out: (max_voxel, num_points, c), coors_out: (max_voxel, 3)\n",
    "            # num_points_per_voxel_out: (max_voxel, )\n",
    "            pillars.append(voxels_out)\n",
    "            coors.append(coors_out.long())\n",
    "            npoints_per_pillar.append(num_points_per_voxel_out)\n",
    "        \n",
    "        pillars = torch.cat(pillars, dim=0) # (p1 + p2 + ... + pb, num_points, c)\n",
    "        npoints_per_pillar = torch.cat(npoints_per_pillar, dim=0) # (p1 + p2 + ... + pb, )\n",
    "        coors_batch = []\n",
    "        for i, cur_coors in enumerate(coors):\n",
    "            coors_batch.append(F.pad(cur_coors, (1, 0), value=i))\n",
    "        coors_batch = torch.cat(coors_batch, dim=0) # (p1 + p2 + ... + pb, 1 + 3)\n",
    "\n",
    "        return pillars, coors_batch, npoints_per_pillar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919dba0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point_range_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/drcl/workspace/Object-Detection-based-Lidar-and-camera/src/detection_pkg/src/lib/PointPillars/Untitled.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/drcl/workspace/Object-Detection-based-Lidar-and-camera/src/detection_pkg/src/lib/PointPillars/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pc_file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(pc_folder_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/drcl/workspace/Object-Detection-based-Lidar-and-camera/src/detection_pkg/src/lib/PointPillars/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pc \u001b[39m=\u001b[39m read_points(pc_folder_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m pc_file_list[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/drcl/workspace/Object-Detection-based-Lidar-and-camera/src/detection_pkg/src/lib/PointPillars/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pc \u001b[39m=\u001b[39m point_range_filter(pc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'point_range_filter' is not defined"
     ]
    }
   ],
   "source": [
    "pc_folder_path = \"dataset/testing/velodyne/\"\n",
    "pc_file_list = os.listdir(pc_folder_path)\n",
    "pc = read_points(pc_folder_path + \"/\" + pc_file_list[0])\n",
    "\n",
    "pc = point_range_filter(pc)\n",
    "# pc_torch = torch.from_numpy(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f415f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8599, 32, 4])\n",
      "torch.Size([8599, 4])\n",
      "torch.Size([8599])\n",
      "tensor([[20.3780,  4.6160,  0.9160,  0.3900],\n",
      "        [20.4490,  4.5740,  0.7840,  0.2900],\n",
      "        [20.3510,  4.6190,  0.7820,  0.3900],\n",
      "        [20.4170,  4.5080,  0.4190,  0.2600],\n",
      "        [20.3700,  4.5640,  0.4180,  0.3900],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
      "tensor([  0, 127, 276,   0], device='cuda:0')\n",
      "tensor(5, device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # np.random.seed(22)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    nclasses=3\n",
    "    voxel_size=[0.16, 0.16, 4]\n",
    "    point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1]\n",
    "    max_num_points=32\n",
    "    max_voxels=(16000, 40000)\n",
    "\n",
    "    test_layer = PillarLayer(voxel_size=voxel_size,\n",
    "                            point_cloud_range=point_cloud_range,\n",
    "                            max_voxels=max_voxels,\n",
    "                            max_num_points=max_num_points)\n",
    "\n",
    "    # pc = np.random.uniform(-2, 8, size=[1000, 4]).astype(np.float32)\n",
    "    pc_tensor = torch.from_numpy(pc).to(device)\n",
    "\n",
    "    pillars, coors_batch, npoints_per_pillar = test_layer([pc_tensor])\n",
    "\n",
    "    print(pillars.size())\n",
    "    print(coors_batch.size())\n",
    "    print(npoints_per_pillar.size())\n",
    "\n",
    "    print(pillars[10])\n",
    "    print(coors_batch[10])\n",
    "    print(npoints_per_pillar[10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37c234c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx, vy = voxel_size[0], voxel_size[1]\n",
    "x_offset = voxel_size[0] / 2 + point_cloud_range[0]\n",
    "y_offset = voxel_size[1] / 2 + point_cloud_range[1]\n",
    "\n",
    "offset_pt_center = pillars[:, :, :3] - torch.sum(pillars[:, :, :3], dim=1, keepdim=True) / npoints_per_pillar[:, None, None] \n",
    "x_offset_pi_center = pillars[:, :, :1] - (coors_batch[:, None, 1:2] * vx + x_offset) # (p1 + p2 + ... + pb, num_points, 1)\n",
    "y_offset_pi_center = pillars[:, :, 1:2] - (coors_batch[:, None, 2:3] * vy + y_offset) # (p1 + p2 + ... + pb, num_points, 1)\n",
    "\n",
    "\n",
    "features = torch.cat([pillars, offset_pt_center, x_offset_pi_center, y_offset_pi_center], dim=-1) # (p1 + p2 + ... + pb, num_points, 9)\n",
    "features[:, :, 0:1] = x_offset_pi_center # tmp\n",
    "features[:, :, 1:2] = y_offset_pi_center # tmp\n",
    "\n",
    "# voxel_ids = torch.arange(0, pillars.size(1)).to(device) # (num_points, )\n",
    "# mask = voxel_ids[:, None] < npoints_per_pillar[None, :] # (num_points, p1 + p2 + ... + pb)\n",
    "# mask = mask.permute(1, 0).contiguous()  # (p1 + p2 + ... + pb, num_points)\n",
    "# features *= mask[:, :, None]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be28663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(9, 64, 1, bias=False).to(device)\n",
    "bn = nn.BatchNorm1d(64, eps=1e-3, momentum=0.01).to(device)\n",
    "# 5. embedding\n",
    "features = features.permute(0, 2, 1).contiguous()\n",
    "features = F.relu(bn(conv(features)))  # (p1 + p2 + ... + pb, out_channels, num_points)\n",
    "pooling_features = torch.max(features, dim=-1)[0] # (p1 + p2 + ... + pb, out_channels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed0cb3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8599, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16ac5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_canvas = []\n",
    "bs = coors_batch[-1, 0] + 1\n",
    "\n",
    "x_l = int((point_cloud_range[3] - point_cloud_range[0]) / voxel_size[0])\n",
    "y_l = int((point_cloud_range[4] - point_cloud_range[1]) / voxel_size[1])\n",
    "\n",
    "for i in range(bs):\n",
    "    cur_coors_idx = coors_batch[:, 0] == i\n",
    "    cur_coors = coors_batch[cur_coors_idx, :]\n",
    "    cur_features = pooling_features[cur_coors_idx]\n",
    "    canvas = torch.zeros((x_l, y_l, 64), dtype=torch.float32, device=device)\n",
    "    canvas[cur_coors[:, 1], cur_coors[:, 2]] = cur_features\n",
    "    canvas = canvas.permute(2, 1, 0).contiguous()\n",
    "    batched_canvas.append(canvas)\n",
    "batched_canvas = torch.stack(batched_canvas, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cff916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel=64\n",
    "out_channels=[64, 128, 256]\n",
    "layer_nums=[3, 5, 5]\n",
    "layer_strides=[2, 2, 2]\n",
    "\n",
    "for i in range(len(layer_strides)):\n",
    "    blocks = []\n",
    "    blocks.append(nn.Conv2d(in_channel, out_channels[i], 3, stride=layer_strides[i], bias=False, padding=1))\n",
    "    blocks.append(nn.BatchNorm2d(out_channels[i], eps=1e-3, momentum=0.01))\n",
    "    blocks.append(nn.ReLU(inplace=True))\n",
    "\n",
    "    for _ in range(layer_nums[i]):\n",
    "        blocks.append(nn.Conv2d(out_channels[i], out_channels[i], 3, bias=False, padding=1))\n",
    "        blocks.append(nn.BatchNorm2d(out_channels[i], eps=1e-3, momentum=0.01))\n",
    "        blocks.append(nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30b8423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = nn.Conv2d(64, 64, 3, stride=2, bias=False, padding=1).to(device)\n",
    "a13 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "a14 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "a15 = nn.Conv2d(64, 64, 3, stride=1, bias=False).to(device)\n",
    "\n",
    "b1 = nn.ConvTranspose2d(64, 128, 1, stride=1, bias=False).to(device)\n",
    "\n",
    "c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66017eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = a1(batched_canvas)\n",
    "test = b1(test)\n",
    "\n",
    "# test = a12(batched_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2ff592e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.1852,  0.3704,  0.5556,  0.7407,  0.9259,  1.1111,  1.2963,\n",
       "         1.4815,  1.6667,  1.8519,  2.0370,  2.2222,  2.4074,  2.5926,  2.7778,\n",
       "         2.9630,  3.1481,  3.3333,  3.5185,  3.7037,  3.8889,  4.0741,  4.2593,\n",
       "         4.4444,  4.6296,  4.8148,  5.0000,  5.1852,  5.3704,  5.5556,  5.7407,\n",
       "         5.9259,  6.1111,  6.2963,  6.4815,  6.6667,  6.8519,  7.0370,  7.2222,\n",
       "         7.4074,  7.5926,  7.7778,  7.9630,  8.1481,  8.3333,  8.5185,  8.7037,\n",
       "         8.8889,  9.0741,  9.2593,  9.4444,  9.6296,  9.8148, 10.0000, 10.1852,\n",
       "        10.3704, 10.5556, 10.7407, 10.9259, 11.1111, 11.2963, 11.4815, 11.6667,\n",
       "        11.8519, 12.0370, 12.2222, 12.4074, 12.5926, 12.7778, 12.9630, 13.1481,\n",
       "        13.3333, 13.5185, 13.7037, 13.8889, 14.0741, 14.2593, 14.4444, 14.6296,\n",
       "        14.8148, 15.0000, 15.1852, 15.3704, 15.5556, 15.7407, 15.9259, 16.1111,\n",
       "        16.2963, 16.4815, 16.6667, 16.8519, 17.0370, 17.2222, 17.4074, 17.5926,\n",
       "        17.7778, 17.9630, 18.1481, 18.3333, 18.5185, 18.7037, 18.8889, 19.0741,\n",
       "        19.2593, 19.4444, 19.6296, 19.8148, 20.0000, 20.1852, 20.3704, 20.5556,\n",
       "        20.7407, 20.9259, 21.1111, 21.2963, 21.4815, 21.6667, 21.8519, 22.0370,\n",
       "        22.2222, 22.4074, 22.5926, 22.7778, 22.9630, 23.1481, 23.3333, 23.5185,\n",
       "        23.7037, 23.8889, 24.0741, 24.2593, 24.4444, 24.6296, 24.8148, 25.0000,\n",
       "        25.1852, 25.3704, 25.5556, 25.7407, 25.9259, 26.1111, 26.2963, 26.4815,\n",
       "        26.6667, 26.8519, 27.0370, 27.2222, 27.4074, 27.5926, 27.7778, 27.9630,\n",
       "        28.1481, 28.3333, 28.5185, 28.7037, 28.8889, 29.0741, 29.2593, 29.4444,\n",
       "        29.6296, 29.8148, 30.0000, 30.1852, 30.3704, 30.5556, 30.7407, 30.9259,\n",
       "        31.1111, 31.2963, 31.4815, 31.6667, 31.8519, 32.0370, 32.2222, 32.4074,\n",
       "        32.5926, 32.7778, 32.9630, 33.1482, 33.3333, 33.5185, 33.7037, 33.8889,\n",
       "        34.0741, 34.2593, 34.4444, 34.6296, 34.8148, 35.0000, 35.1852, 35.3704,\n",
       "        35.5556, 35.7407, 35.9259, 36.1111, 36.2963, 36.4815, 36.6667, 36.8519,\n",
       "        37.0370, 37.2222, 37.4074, 37.5926, 37.7778, 37.9630, 38.1481, 38.3333,\n",
       "        38.5185, 38.7037, 38.8889, 39.0741, 39.2593, 39.4444, 39.6296, 39.8148,\n",
       "        40.0000])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 40, 216 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "010b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [[0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "            [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "            [0, -39.68, -1.78, 69.12, 39.68, -1.78]]\n",
    "# ranges = [[0, -39.68, 0.6, 69.12, 39.68, 0.6],\n",
    "#             [0, -39.68, 0.6, 69.12, 39.68, 0.6],\n",
    "#             [0, -39.68, 1.78, 69.12, 39.68, 1.78]]\n",
    "sizes = [[0.6, 0.8, 1.73], [0.6, 1.76, 1.73], [1.6, 3.9, 1.56]]\n",
    "rotations=[0, 1.57]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rotations = torch.tensor(rotations, device=device)\n",
    "# anchor_range = ranges[0]\n",
    "anchor_range = [0, 0, -0.6, 10., 10., -0.6]\n",
    "anchor_size = torch.tensor([0.6, 0.8, 1.73],device=device)\n",
    "\n",
    "feature_map_size = (3,3)\n",
    "\n",
    "x_centers = torch.linspace(anchor_range[0], anchor_range[3], feature_map_size[1] + 1, device=device)\n",
    "y_centers = torch.linspace(anchor_range[1], anchor_range[4], feature_map_size[0] + 1, device=device)\n",
    "z_centers = torch.linspace(anchor_range[2], anchor_range[5], 1 + 1, device=device)\n",
    "\n",
    "\n",
    "x_shift = (x_centers[1] - x_centers[0]) / 2\n",
    "y_shift = (y_centers[1] - y_centers[0]) / 2\n",
    "z_shift = (z_centers[1] - z_centers[0]) / 2\n",
    "x_centers = x_centers[:feature_map_size[1]] + x_shift # (feature_map_size[1], )\n",
    "y_centers = y_centers[:feature_map_size[0]] + y_shift # (feature_map_size[0], )\n",
    "z_centers = z_centers[:1] + z_shift  # (1, )\n",
    "\n",
    "meshgrids = torch.meshgrid(x_centers, y_centers, z_centers, rotations)\n",
    "meshgrids = list(meshgrids)\n",
    "for i in range(len(meshgrids)):\n",
    "    meshgrids[i] = meshgrids[i][..., None] # [feature_map_size[1], feature_map_size[0], 1, 2, 1]\n",
    "\n",
    "anchor_size = anchor_size[None, None, None, None, :]\n",
    "repeat_shape = [feature_map_size[1], feature_map_size[0], 1, len(rotations), 1]\n",
    "anchor_size = anchor_size.repeat(repeat_shape) # [feature_map_size[1], feature_map_size[0], 1, 2, 3]\n",
    "meshgrids.insert(3, anchor_size)\n",
    "anchors = torch.cat(meshgrids, dim=-1).permute(2, 1, 0, 3, 4).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3fd6d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_size.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c88be24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 2, 7])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132e29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pillars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a272d058f02466131663a98fde0a5fb028fb2427dbe553090c2dd1c9aa10e44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
