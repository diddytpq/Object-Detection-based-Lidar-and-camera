{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drcl/anaconda3/envs/mmlab/lib/python3.8/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/drcl/anaconda3/envs/mmlab/lib/python3.8/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda-11.3/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/drcl/anaconda3/envs/mmlab/lib/python3.8/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda-11.3/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tool.dataset import clocs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stage2_training(boxes, query_boxes, criterion, scores_3d, scores_2d, dis_to_lidar_3d,overlaps,tensor_index):\n",
    "    N = boxes.shape[0] #20000\n",
    "    print(N)\n",
    "    K = query_boxes.shape[0] #30\n",
    "    print(K)\n",
    "    max_num = 900000\n",
    "    ind=0\n",
    "    ind_max = ind\n",
    "    for k in range(K):\n",
    "        qbox_area = ((query_boxes[k, 2] - query_boxes[k, 0]) *\n",
    "                     (query_boxes[k, 3] - query_boxes[k, 1]))\n",
    "        for n in range(N):\n",
    "            iw = (min(boxes[n, 2], query_boxes[k, 2]) -\n",
    "                  max(boxes[n, 0], query_boxes[k, 0]))\n",
    "            if iw > 0:\n",
    "                ih = (min(boxes[n, 3], query_boxes[k, 3]) -\n",
    "                      max(boxes[n, 1], query_boxes[k, 1]))\n",
    "                if ih > 0:\n",
    "                    if criterion == -1:\n",
    "                        ua = (\n",
    "                            (boxes[n, 2] - boxes[n, 0]) *\n",
    "                            (boxes[n, 3] - boxes[n, 1]) + qbox_area - iw * ih)\n",
    "                    elif criterion == 0:\n",
    "                        ua = ((boxes[n, 2] - boxes[n, 0]) *\n",
    "                              (boxes[n, 3] - boxes[n, 1]))\n",
    "                    elif criterion == 1:\n",
    "                        ua = qbox_area\n",
    "                    else:\n",
    "                        ua = 1.0\n",
    "                    overlaps[ind,0] = iw * ih / ua #IOU\n",
    "                    overlaps[ind,1] = scores_3d[n]\n",
    "                    overlaps[ind,2] = scores_2d[k,0]\n",
    "                    overlaps[ind,3] = dis_to_lidar_3d[n,0]\n",
    "                    tensor_index[ind,0] = k\n",
    "                    tensor_index[ind,1] = n\n",
    "                    ind = ind+1\n",
    "\n",
    "                elif k==K-1:\n",
    "                    overlaps[ind,0] = -10\n",
    "                    overlaps[ind,1] = scores_3d[n]\n",
    "                    overlaps[ind,2] = -10\n",
    "                    overlaps[ind,3] = dis_to_lidar_3d[n,0]\n",
    "                    tensor_index[ind,0] = k\n",
    "                    tensor_index[ind,1] = n\n",
    "                    ind = ind+1\n",
    "            elif k==K-1:\n",
    "                overlaps[ind,0] = -10\n",
    "                overlaps[ind,1] = scores_3d[n]\n",
    "                overlaps[ind,2] = -10\n",
    "                overlaps[ind,3] = dis_to_lidar_3d[n,0]\n",
    "                tensor_index[ind,0] = k\n",
    "                tensor_index[ind,1] = n\n",
    "                ind = ind+1\n",
    "    if ind > ind_max:\n",
    "        ind_max = ind\n",
    "    return overlaps, tensor_index, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clocs_data(Dataset):\n",
    "\n",
    "    def __init__(self, _2d_path, _3d_path, index_path, input_data, infopath = '../data/clocs_data/info/kitti_infos_trainval.pkl', val = False):\n",
    "\n",
    "        self._2d_path = _2d_path \n",
    "        self._3d_path = _3d_path \n",
    "        f = open(index_path, \"r\")\n",
    "        self.ind = f.read().splitlines()\n",
    "        f.close()\n",
    "        self.val = val #False\n",
    "        self.input_data = input_data #input data path\n",
    "        self.anno = pickle.load(open(infopath,'rb'))\n",
    "        self.id2ind = np.zeros(len(self.anno))\n",
    "        # self.id2ind[img_id] = number in self.anno\n",
    "        for i in range(len(self.anno)):\n",
    "            # print(self.anno[i])\n",
    "            self.id2ind[int(self.anno[i]['image_idx'])] = i\n",
    "\n",
    "    def generate_input(self):\n",
    "        input_path = Path(self.input_data)\n",
    "\n",
    "        # for i in tqdm(range(len(self.ind))):\n",
    "        for i in range(1):\n",
    "            \n",
    "            i = 7\n",
    "\n",
    "            # find 2d detection\n",
    "            detection_2d_file_name = self._2d_path+\"/\"+self.ind[i]+\".txt\"\n",
    "            print(\"detection_2d_file_name :\",detection_2d_file_name)\n",
    "\n",
    "            with open(detection_2d_file_name, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "\n",
    "            # print(\"content : \\n\",content)\n",
    "\n",
    "            predicted_class = np.array([x[0] for x in content],dtype='object')\n",
    "            predicted_class_index = np.where(predicted_class=='Car')\n",
    "\n",
    "            detection_result = np.array([[float(info) for info in x[4:8]] for x in content]).reshape(-1, 4)\n",
    "            score = np.array([float(x[15]) for x in content])  # 1000 is the score scale!!!\n",
    "\n",
    "            f_detection_result=np.append(detection_result,score.reshape(-1,1),1)\n",
    "\n",
    "            # print(\"f_detection_result \\n\", f_detection_result)\n",
    "            # print(f_detection_result.shape)\n",
    "\n",
    "            middle_predictions=f_detection_result[predicted_class_index,:].reshape(-1,5)\n",
    "\n",
    "            # print(\"middle_predictions \\n\", middle_predictions)\n",
    "            # print(middle_predictions.shape)\n",
    "\n",
    "            top_predictions=middle_predictions[np.where(middle_predictions[:,4]>=-100)]\n",
    "\n",
    "            # print(\"top_predictions \\n\", top_predictions)\n",
    "            # print(top_predictions.shape)\n",
    "\n",
    "            _3d_result = torch.load(self._3d_path+\"/\"+self.ind[i]+\".pt\")[0]\n",
    "\n",
    "            # print(\"_3d_result \\n\", _3d_result)\n",
    "\n",
    "            res, iou_test, tensor_index = self.train_stage_2(_3d_result, top_predictions)\n",
    "\n",
    "            all_3d_output_camera_dict, fusion_input,tensor_index = res, iou_test, tensor_index\n",
    "\n",
    "            # get 3d anno\n",
    "            int_ind = int(self.id2ind[i])\n",
    "            gt_anno = self.anno[int_ind]['annos']\n",
    "            d3_gt_boxes = self.process_anno(gt_anno)\n",
    "\n",
    "            d3_gt_boxes_camera=d3_gt_boxes\n",
    "            if d3_gt_boxes.shape[0] == 0:\n",
    "                target_for_fusion = np.zeros((1,20000,1))\n",
    "                positive_index = np.zeros((1,20000),dtype=np.float32)\n",
    "                negative_index = np.zeros((1,20000),dtype=np.float32)\n",
    "                negative_index[:,:] = 1\n",
    "                \n",
    "            else:\n",
    "                ###### predicted bev boxes\n",
    "                pred_3d_box = all_3d_output_camera_dict[0][\"box3d_camera\"]\n",
    "\n",
    "                print(\"d3_gt_boxes_camera \\n\",d3_gt_boxes_camera)\n",
    "                print(\"pred_3d_box \\n\",pred_3d_box)\n",
    "\n",
    "\n",
    "                iou_bev = d3_box_overlap(d3_gt_boxes_camera, pred_3d_box, criterion=-1)\n",
    "                iou_bev_max = np.amax(iou_bev,axis=0)\n",
    "                # print(np.max(iou_bev_max))\n",
    "                target_for_fusion = ((iou_bev_max >= 0.7)*1).reshape(1,-1,1)\n",
    "\n",
    "                positive_index = ((iou_bev_max >= 0.7)*1).reshape(1,-1)\n",
    "                negative_index = ((iou_bev_max <= 0.5)*1).reshape(1,-1)\n",
    "            \n",
    "    def train_stage_2(self, _3d_result,top_predictions):\n",
    "        box_preds = _3d_result['boxes_lidar']\n",
    "        final_box_preds = box_preds\n",
    "        predictions_dicts = []\n",
    "        locs = _3d_result['location'] # xyz\n",
    "        dims = _3d_result['dimensions'] # hwl\n",
    "        angles = _3d_result['rotation_y'].reshape(-1,1)\n",
    "        final_box_preds_camera = np.concatenate((locs,dims,angles),axis=1)\n",
    "\n",
    "        # print(\"final_box_preds_camera \\n\",final_box_preds_camera)\n",
    "        print(\"final_box_preds \\n\",final_box_preds)\n",
    "\n",
    "\n",
    "        box_2d_preds = _3d_result['bbox']\n",
    "        final_scores = _3d_result['score']\n",
    "        img_idx = _3d_result['frame_id']\n",
    "        # predictions\n",
    "        predictions_dict = {\n",
    "            \"bbox\": box_2d_preds,\n",
    "            \"box3d_camera\": final_box_preds_camera,\n",
    "            \"box3d_lidar\": final_box_preds,\n",
    "            \"scores\": final_scores,\n",
    "            #\"label_preds\": label_preds,\n",
    "            \"image_idx\": img_idx,\n",
    "        }\n",
    "\n",
    "        predictions_dicts.append(predictions_dict)\n",
    "        # normalization 된 라이다와 박스 사이의 직선 거리   \n",
    "        dis_to_lidar = torch.norm(torch.tensor(box_preds[:,:2]),p=2,dim=1,keepdim=True).numpy()/82.0 \n",
    "\n",
    "        box_2d_detector = np.zeros((200, 4))\n",
    "        box_2d_detector[0:top_predictions.shape[0],:]=top_predictions[:,:4]\n",
    "        box_2d_detector = top_predictions[:,:4]\n",
    "        box_2d_scores = top_predictions[:,4].reshape(-1,1)\n",
    "        overlaps1 = np.zeros((900000,4),dtype=np.float32)\n",
    "        tensor_index1 = np.zeros((900000,2),dtype=np.float32)\n",
    "        overlaps1[:,:] = -1.0\n",
    "        tensor_index1[:,:] = -1.0\n",
    "\n",
    "\n",
    "        iou_test,tensor_index, max_num = build_stage2_training(box_2d_preds,\n",
    "                                    box_2d_detector,\n",
    "                                    -1,\n",
    "                                    final_scores,\n",
    "                                    box_2d_scores,\n",
    "                                    dis_to_lidar,\n",
    "                                    overlaps1,\n",
    "                                    tensor_index1)\n",
    "        print(\"box_2d_detector \\n\", box_2d_detector)\n",
    "        print(\"iou_test \\n\", iou_test[:max_num])\n",
    "        print(\"tensor_index \\n\", tensor_index[:max_num])\n",
    "        print(\"max_num\\n\", max_num)\n",
    "\n",
    "        iou_test_tensor = torch.FloatTensor(iou_test)  #iou_test_tensor shape: [160000,4]\n",
    "        tensor_index_tensor = torch.LongTensor(tensor_index)\n",
    "        iou_test_tensor = iou_test_tensor.permute(1,0)\n",
    "\n",
    "        iou_test_tensor = iou_test_tensor.reshape(4,900000)\n",
    "\n",
    "        tensor_index_tensor = tensor_index_tensor.reshape(-1,2)\n",
    "\n",
    "        if max_num == 0:\n",
    "            non_empty_iou_test_tensor = torch.zeros(4,2)\n",
    "            non_empty_iou_test_tensor[:,:] = -1\n",
    "            non_empty_tensor_index_tensor = torch.zeros(2,2)\n",
    "            non_empty_tensor_index_tensor[:,:] = -1\n",
    "        else:\n",
    "            non_empty_iou_test_tensor = iou_test_tensor[:,:max_num]\n",
    "            non_empty_tensor_index_tensor = tensor_index_tensor[:max_num,:]\n",
    "\n",
    "        return predictions_dicts, non_empty_iou_test_tensor, non_empty_tensor_index_tensor\n",
    "\n",
    "    def process_anno(self, anno, class_name=['Car']):\n",
    "        ind = np.where(anno['name'] == class_name[0])\n",
    "        loc = anno['location'][ind]\n",
    "        dim = anno['dimensions'][ind]\n",
    "        rot = anno['rotation_y'][ind]\n",
    "        if len(loc) == 0:\n",
    "            d3_box = []\n",
    "        else:\n",
    "            d3_box = np.concatenate((loc,dim,rot.reshape(-1,1)),axis=1)\n",
    "        return np.array(d3_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './index/trainval.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train_ind_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./index/trainval.txt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m infopath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/clocs_data/info/kitti_infos_trainval.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m train_dataset \u001b[39m=\u001b[39m clocs_data(_2d_path, _3d_path,train_ind_path, input_data, infopath)\n",
      "Cell \u001b[0;32mIn [5], line 7\u001b[0m, in \u001b[0;36mclocs_data.__init__\u001b[0;34m(self, _2d_path, _3d_path, index_path, input_data, infopath, val)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_2d_path \u001b[39m=\u001b[39m _2d_path \n\u001b[1;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_3d_path \u001b[39m=\u001b[39m _3d_path \n\u001b[0;32m----> 7\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(index_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mind \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m      9\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './index/trainval.txt'"
     ]
    }
   ],
   "source": [
    "_2d_path = './data/clocs_data/2D'\n",
    "_3d_path = './data/clocs_data/3D'\n",
    "input_data = './data/clocs_data/input_data'\n",
    "train_ind_path = './index/trainval.txt'\n",
    "infopath = './data/clocs_data/info/kitti_infos_trainval.pkl'\n",
    "\n",
    "train_dataset = clocs_data(_2d_path, _3d_path,train_ind_path, input_data, infopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion_input\n",
      " tensor([[[[ 2.4300e-02,  5.5168e-02,  1.0081e-01,  6.1437e-03,  2.5525e-02,\n",
      "            7.2263e-02,  6.0891e-02, -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 1.0937e-01,  1.0937e-01,  1.5447e-01,  1.5447e-01,  1.5447e-01,\n",
      "            1.0937e-01,  1.0937e-01,  1.5447e-01,  1.0937e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00, -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 8.4841e-02,  8.4841e-02,  7.8425e-02,  7.8425e-02,  7.8425e-02,\n",
      "            8.4841e-02,  8.4841e-02,  7.8425e-02,  8.4841e-02]]]])\n",
      "torch.Size([1, 4, 1, 9])\n",
      "tensor_index\n",
      " tensor([[[17,  1],\n",
      "         [19,  1],\n",
      "         [20,  0],\n",
      "         [23,  0],\n",
      "         [25,  0],\n",
      "         [28,  1],\n",
      "         [29,  1],\n",
      "         [32,  0],\n",
      "         [32,  1]]])\n",
      "torch.Size([1, 9, 2])\n",
      "positives\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([0])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000000']\n",
      "fusion_input\n",
      " tensor([[[[ 7.2167e-01,  7.3303e-01,  7.2555e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 5.9277e-01,  5.3812e-01,  5.1268e-01,  ...,  4.9636e-03,\n",
      "            4.9636e-03,  4.9636e-03]],\n",
      "\n",
      "         [[ 8.4440e-01,  8.4440e-01,  8.4440e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 7.4604e-01,  7.4717e-01,  7.4371e-01,  ...,  8.1679e-01,\n",
      "            8.1457e-01,  8.1247e-01]]]])\n",
      "torch.Size([1, 4, 1, 30345])\n",
      "tensor_index\n",
      " tensor([[[    0,     0],\n",
      "         [    0,     1],\n",
      "         [    0,     2],\n",
      "         ...,\n",
      "         [   11, 19997],\n",
      "         [   11, 19998],\n",
      "         [   11, 19999]]])\n",
      "torch.Size([1, 30345, 2])\n",
      "positives\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[0., 0., 0.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([1])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000001']\n",
      "fusion_input\n",
      " tensor([[[[ 8.1892e-01,  8.3061e-01,  8.3887e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 8.7180e-01,  8.6261e-01,  8.5546e-01,  ...,  3.7886e-03,\n",
      "            3.7885e-03,  3.7884e-03]],\n",
      "\n",
      "         [[ 9.9880e-01,  9.9880e-01,  9.9880e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 4.2664e-01,  4.2658e-01,  4.2638e-01,  ...,  1.6633e-01,\n",
      "            4.5649e-02,  4.4409e-01]]]])\n",
      "torch.Size([1, 4, 1, 56904])\n",
      "tensor_index\n",
      " tensor([[[    0,     0],\n",
      "         [    0,     1],\n",
      "         [    0,     2],\n",
      "         ...,\n",
      "         [   31, 19997],\n",
      "         [   31, 19998],\n",
      "         [   31, 19999]]])\n",
      "torch.Size([1, 56904, 2])\n",
      "positives\n",
      " tensor([[1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[0., 0., 0.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([1])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000002']\n",
      "fusion_input\n",
      " tensor([[[[ 2.3194e-01,  2.6432e-02,  4.1512e-02, -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 1.4162e-01,  1.0542e-01,  1.0542e-01,  1.4162e-01,  1.0542e-01]],\n",
      "\n",
      "         [[ 1.0000e+00,  5.2000e-03,  1.0000e-04, -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 8.3455e-02,  8.9925e-02,  8.9925e-02,  8.3455e-02,  8.9925e-02]]]])\n",
      "torch.Size([1, 4, 1, 5])\n",
      "tensor_index\n",
      " tensor([[[ 0,  0],\n",
      "         [ 3,  1],\n",
      "         [21,  1],\n",
      "         [31,  0],\n",
      "         [31,  1]]])\n",
      "torch.Size([1, 5, 2])\n",
      "positives\n",
      " tensor([[0., 0.]])\n",
      "torch.Size([1, 2])\n",
      "negatives\n",
      " tensor([[1., 1.]])\n",
      "torch.Size([1, 2])\n",
      "one_hot_targets\n",
      " tensor([[[0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 2, 1])\n",
      "label_n\n",
      " tensor([1])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000003']\n",
      "fusion_input\n",
      " tensor([[[[ 9.0757e-01,  9.2217e-01,  8.9265e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 9.1310e-01,  9.1226e-01,  8.9729e-01,  ...,  5.4416e-03,\n",
      "            5.4401e-03,  5.4395e-03]],\n",
      "\n",
      "         [[ 9.9970e-01,  9.9970e-01,  9.9970e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 5.0679e-01,  5.0665e-01,  5.0685e-01,  ...,  7.0215e-01,\n",
      "            3.2111e-01,  7.4319e-01]]]])\n",
      "torch.Size([1, 4, 1, 38916])\n",
      "tensor_index\n",
      " tensor([[[    0,     0],\n",
      "         [    0,     1],\n",
      "         [    0,     2],\n",
      "         ...,\n",
      "         [   20, 19997],\n",
      "         [   20, 19998],\n",
      "         [   20, 19999]]])\n",
      "torch.Size([1, 38916, 2])\n",
      "positives\n",
      " tensor([[1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[0., 0., 0.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([2])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000004']\n",
      "fusion_input\n",
      " tensor([[[[ 1.5636e-01,  3.4402e-03,  1.3936e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 3.6781e-02,  3.4662e-02,  3.4464e-02,  ...,  4.6360e-03,\n",
      "            4.6359e-03,  4.6357e-03]],\n",
      "\n",
      "         [[ 1.4100e-02,  1.4100e-02,  1.4100e-02,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 3.7153e-01,  7.0979e-02,  3.6839e-01,  ...,  4.2522e-01,\n",
      "            6.2755e-01,  3.8867e-01]]]])\n",
      "torch.Size([1, 4, 1, 36121])\n",
      "tensor_index\n",
      " tensor([[[    0,   136],\n",
      "         [    0,   159],\n",
      "         [    0,   161],\n",
      "         ...,\n",
      "         [   22, 19997],\n",
      "         [   22, 19998],\n",
      "         [   22, 19999]]])\n",
      "torch.Size([1, 36121, 2])\n",
      "positives\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([0])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000005']\n",
      "fusion_input\n",
      " tensor([[[[ 8.7207e-01,  8.8277e-01,  8.8236e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 9.5642e-01,  9.4995e-01,  9.4937e-01,  ...,  6.0745e-03,\n",
      "            6.0742e-03,  6.0739e-03]],\n",
      "\n",
      "         [[ 9.9980e-01,  9.9980e-01,  9.9980e-01,  ..., -1.0000e+01,\n",
      "           -1.0000e+01, -1.0000e+01]],\n",
      "\n",
      "         [[ 3.9027e-01,  3.9018e-01,  3.9012e-01,  ...,  7.0178e-01,\n",
      "            4.5799e-02,  7.0629e-01]]]])\n",
      "torch.Size([1, 4, 1, 92403])\n",
      "tensor_index\n",
      " tensor([[[    0,     3],\n",
      "         [    0,     5],\n",
      "         [    0,     6],\n",
      "         ...,\n",
      "         [   57, 19997],\n",
      "         [   57, 19998],\n",
      "         [   57, 19999]]])\n",
      "torch.Size([1, 92403, 2])\n",
      "positives\n",
      " tensor([[1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 20000])\n",
      "negatives\n",
      " tensor([[0., 0., 0.,  ..., 1., 1., 1.]])\n",
      "torch.Size([1, 20000])\n",
      "one_hot_targets\n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "torch.Size([1, 20000, 1])\n",
      "label_n\n",
      " tensor([4])\n",
      "torch.Size([1])\n",
      "idx\n",
      " ['000006']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for fusion_input,tensor_index,positives,negatives,one_hot_targets,label_n,idx in (train_data):\n",
    "    print(\"fusion_input\\n\",fusion_input)\n",
    "    print(fusion_input.shape)\n",
    "\n",
    "    print(\"tensor_index\\n\",tensor_index)\n",
    "    print(tensor_index.shape)\n",
    "\n",
    "    print(\"positives\\n\",positives)\n",
    "    print(positives.shape)\n",
    "    \n",
    "    print(\"negatives\\n\",negatives)\n",
    "    print(negatives.shape)\n",
    "\n",
    "    print(\"one_hot_targets\\n\",one_hot_targets)\n",
    "    print(one_hot_targets.shape)\n",
    "\n",
    "    print(\"label_n\\n\",label_n)\n",
    "    print(label_n.shape)\n",
    "\n",
    "    print(\"idx\\n\",idx)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if count == 7 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_data': {'fusion_input': array([[ 3.4720402e-02,  6.5608583e-03,  2.2248727e-04,  1.5097714e-04,\n",
       "           6.7675374e-03, -1.0000000e+01],\n",
       "         [ 1.5373568e-01,  1.1602955e-01,  1.1602955e-01,  1.1602955e-01,\n",
       "           1.5373568e-01,  1.1602955e-01],\n",
       "         [ 9.9980003e-01,  9.9919999e-01,  1.3300000e-01,  5.0000002e-04,\n",
       "           0.0000000e+00, -1.0000000e+01],\n",
       "         [ 8.3436064e-02,  8.4934637e-02,  8.4934637e-02,  8.4934637e-02,\n",
       "           8.3436064e-02,  8.4934637e-02]], dtype=float32),\n",
       "  'tensor_index': array([[ 0,  0],\n",
       "         [ 1,  1],\n",
       "         [ 2,  1],\n",
       "         [16,  1],\n",
       "         [25,  0],\n",
       "         [25,  1]])},\n",
       " 'label': {'target_for_fusion': tensor([[[0],\n",
       "           [0]]]),\n",
       "  'positive_index': tensor([[0, 0]]),\n",
       "  'negative_index': tensor([[1, 1]]),\n",
       "  'label_n': 3}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(\"./data/clocs_data/input_data/000007.pt\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cls_weights = negatives.type(torch.float32) * 1.0\n",
    "cls_weights = negative_cls_weights + 1.0 * positives.type(torch.float32)\n",
    "pos_normalizer = positives.sum(1, keepdim=True).type(torch.float32)\n",
    "cls_weights /= torch.clamp(pos_normalizer, min=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20000.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives.sum(1, keepdim=True).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor_index.reshape(-1,2).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = torch.zeros(1,200,20000)\n",
    "out_1[:,:,:] = -9999999\n",
    "\n",
    "x = torch.randn(1,1,1,92403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [92403] cannot be broadcast to indexing result of shape [1, 1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_1[:,tensor_index[:,\u001b[39m0\u001b[39;49m],tensor_index[:,\u001b[39m1\u001b[39;49m]] \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m,:,\u001b[39m0\u001b[39m,:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [92403] cannot be broadcast to indexing result of shape [1, 1, 2]"
     ]
    }
   ],
   "source": [
    "out_1[:,tensor_index[:,0],tensor_index[:,1]] = x[0,:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"/media/drcl/DATADRIVE1/kitti/clocs/data/clocs_data/input_data/000189.pt\")\n",
    "b = torch.load(\"./data/clocs_data/test/000189.pt\")\n",
    "\n",
    "a[\"input_data\"][\"fusion_input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"input_data\"][\"fusion_input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = np.array([[1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.4720402e-02,  6.5608583e-03,  2.2248727e-04,  1.5097714e-04,\n",
       "         6.7675374e-03, -1.0000000e+01],\n",
       "       [ 1.5373568e-01,  1.1602955e-01,  1.1602955e-01,  1.1602955e-01,\n",
       "         1.5373568e-01,  1.1602955e-01],\n",
       "       [ 9.9980003e-01,  9.9919999e-01,  1.3300000e-01,  5.0000002e-04,\n",
       "         0.0000000e+00, -1.0000000e+01],\n",
       "       [ 8.3436064e-02,  8.4934637e-02,  8.4934637e-02,  8.4934637e-02,\n",
       "         8.3436064e-02,  8.4934637e-02]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data']['fusion_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input_data']['fusion_input'] = np.vstack([data['input_data']['fusion_input'],score_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data']['fusion_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"000003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [ 2,  1],\n",
       "       [16,  1],\n",
       "       [25,  0],\n",
       "       [25,  1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data'][\"tensor_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('/media/drcl/DATADRIVE1/kitti/clocs/data/clocs_data/3D_box_points/000304.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load(\"/media/drcl/DATADRIVE1/kitti/clocs/data/clocs_data/3D/000304.pt\")\n",
    "b = torch.load(\"/media/drcl/DATADRIVE1/kitti/clocs/data/clocs_data/input_data/000304.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_data': {'fusion_input': array([[-1., -1.],\n",
       "         [-1., -1.],\n",
       "         [-1., -1.],\n",
       "         [-1., -1.]], dtype=float32),\n",
       "  'tensor_index': array([[-1., -1.],\n",
       "         [-1., -1.]], dtype=float32)},\n",
       " 'label': {'target_for_fusion': tensor([], size=(1, 0, 1), dtype=torch.int64),\n",
       "  'positive_index': tensor([], size=(1, 0), dtype=torch.int64),\n",
       "  'negative_index': tensor([], size=(1, 0), dtype=torch.int64),\n",
       "  'label_n': 1}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['input_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load(\"./log/5-Adadelta/faster/result/10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3769"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': array(['Car', 'Car'], dtype='<U3'),\n",
       " 'truncated': array([0., 0.]),\n",
       " 'occluded': array([0., 0.]),\n",
       " 'alpha': array([-4.8127623, -4.550305 ], dtype=float32),\n",
       " 'bbox': array([[656.94366, 188.31335, 701.9653 , 223.98334],\n",
       "        [657.2818 , 192.56345, 700.6856 , 222.95459]], dtype=float32),\n",
       " 'dimensions': array([[4.0677466, 1.5192277, 1.7264566],\n",
       "        [4.2963185, 1.4224142, 1.6721627]], dtype=float32),\n",
       " 'location': array([[ 3.2207198,  2.3027563, 34.54227  ],\n",
       "        [ 3.7493799,  2.550825 , 39.0307   ]], dtype=float32),\n",
       " 'rotation_y': array([-4.7213397, -4.4560156], dtype=float32),\n",
       " 'score': array([0.71337813, 0.2413632 ], dtype=float32),\n",
       " 'boxes_lidar': array([[34.838104 , -3.1938841, -2.0477982,  4.0677466,  1.7264566,\n",
       "          1.5192277,  3.1505432],\n",
       "        [39.32901  , -3.7193356, -2.254514 ,  4.2963185,  1.6721627,\n",
       "          1.4224142,  2.885219 ]], dtype=float32),\n",
       " 'frame_id': '000002'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/drcl/DATADRIVE1/kitti/clocs/data/clocs_data/info/data.pickle\",\"rb\") as fr:\n",
    "    data = pickle.load(fr)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d3e592bd00c2443c54b402565f4e91bc2b5543f7c244ee29cffdc8801b76f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
